{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>FIRST_CAREUNIT</th>\n",
       "      <th>LAST_CAREUNIT</th>\n",
       "      <th>FIRST_WARDID</th>\n",
       "      <th>LAST_WARDID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>OUTTIME</th>\n",
       "      <th>LOS</th>\n",
       "      <th>...</th>\n",
       "      <th>diagnosisstring</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>first_careunit</th>\n",
       "      <th>last_careunit</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los</th>\n",
       "      <th>anchor_age</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027140.0</td>\n",
       "      <td>3011529.0</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2152-07-23 05:34:12</td>\n",
       "      <td>2152-07-24 18:37:32</td>\n",
       "      <td>1.5440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027482.0</td>\n",
       "      <td>3011175.0</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2162-03-20 17:22:48</td>\n",
       "      <td>2162-03-22 18:26:10</td>\n",
       "      <td>2.0440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011746.0</td>\n",
       "      <td>3013234.0</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2107-07-28 17:22:31</td>\n",
       "      <td>2107-08-01 11:03:44</td>\n",
       "      <td>3.7370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010325.0</td>\n",
       "      <td>3022526.0</td>\n",
       "      <td>metavision</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2145-02-06 02:15:08</td>\n",
       "      <td>2145-02-07 18:47:37</td>\n",
       "      <td>1.6892</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012708.0</td>\n",
       "      <td>3035542.0</td>\n",
       "      <td>metavision</td>\n",
       "      <td>SICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2175-02-20 07:41:28</td>\n",
       "      <td>2175-02-23 10:21:01</td>\n",
       "      <td>3.1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  ICUSTAY_ID    DBSOURCE FIRST_CAREUNIT LAST_CAREUNIT  \\\n",
       "0   1027140.0   3011529.0     carevue            CCU           CCU   \n",
       "1   1027482.0   3011175.0     carevue           MICU          MICU   \n",
       "2   1011746.0   3013234.0     carevue           MICU          MICU   \n",
       "3   1010325.0   3022526.0  metavision           MICU          MICU   \n",
       "4   1012708.0   3035542.0  metavision           SICU          SICU   \n",
       "\n",
       "   FIRST_WARDID  LAST_WARDID               INTIME             OUTTIME     LOS  \\\n",
       "0          57.0         57.0  2152-07-23 05:34:12 2152-07-24 18:37:32  1.5440   \n",
       "1          12.0         12.0  2162-03-20 17:22:48 2162-03-22 18:26:10  2.0440   \n",
       "2          52.0         52.0  2107-07-28 17:22:31 2107-08-01 11:03:44  3.7370   \n",
       "3          52.0         52.0  2145-02-06 02:15:08 2145-02-07 18:47:37  1.6892   \n",
       "4          33.0         33.0  2175-02-20 07:41:28 2175-02-23 10:21:01  3.1108   \n",
       "\n",
       "   ... diagnosisstring subject_id stay_id first_careunit last_careunit  \\\n",
       "0  ...             NaN        NaN     NaN            NaN           NaN   \n",
       "1  ...             NaN        NaN     NaN            NaN           NaN   \n",
       "2  ...             NaN        NaN     NaN            NaN           NaN   \n",
       "3  ...             NaN        NaN     NaN            NaN           NaN   \n",
       "4  ...             NaN        NaN     NaN            NaN           NaN   \n",
       "\n",
       "   intime  outtime  los  anchor_age  dod  \n",
       "0     NaT      NaT  NaN         NaN  NaT  \n",
       "1     NaT      NaT  NaN         NaN  NaT  \n",
       "2     NaT      NaT  NaN         NaN  NaT  \n",
       "3     NaT      NaT  NaN         NaN  NaT  \n",
       "4     NaT      NaT  NaN         NaN  NaT  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('../train/pooled_df.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'ICUSTAY_ID', 'DBSOURCE', 'FIRST_CAREUNIT',\n",
      "       'LAST_CAREUNIT', 'FIRST_WARDID', 'LAST_WARDID', 'INTIME', 'OUTTIME',\n",
      "       'LOS', 'GENDER', 'DOB', 'DOD', 'DOD_HOSP', 'DOD_SSN', 'EXPIRE_FLAG',\n",
      "       'age', 'readmission', 'mortality', 'los_3day', 'los_7day', 'ICD9_CODE',\n",
      "       '12h_obs', '24h_obs', 'ID', 'code_name', 'code_offset', 'value', 'uom',\n",
      "       'code_order', 'seq_len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 436M/436M [00:31<00:00, 13.9MB/s] \n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def embed(input_text):\n",
    "    tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    embeddings = model(**tokens).last_hidden_state\n",
    "    pooled_embeddings = embeddings.mean(dim=1)\n",
    "    return pooled_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(0.4792, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.1914, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.1914, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.4965, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.4965, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.4965, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.4965, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.4965, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2712, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2643, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(0.2717, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.6810, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(1.1748, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.5084, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2430, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2712, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.6810, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2712, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(1.1748, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.5084, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0328, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0    \\\n",
       "0  [[tensor(0.4792, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2717, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 1    \\\n",
       "0  [[tensor(0.1914, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.6810, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 2    \\\n",
       "0  [[tensor(0.1914, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(1.1748, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 3    \\\n",
       "0  [[tensor(0.4965, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.5084, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 4    \\\n",
       "0  [[tensor(0.4965, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2430, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 5    \\\n",
       "0  [[tensor(0.4965, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2712, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 6    \\\n",
       "0  [[tensor(0.4965, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.6810, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 7    \\\n",
       "0  [[tensor(0.4965, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2712, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 8    \\\n",
       "0  [[tensor(0.2712, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(1.1748, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 9    ...  \\\n",
       "0  [[tensor(0.2643, grad_fn=<UnbindBackward0>), t...  ...   \n",
       "1  [[tensor(0.5084, grad_fn=<UnbindBackward0>), t...  ...   \n",
       "\n",
       "                                                 140  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 141  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 142  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 143  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 144  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 145  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 146  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 147  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 148  \\\n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 149  \n",
       "0  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...  \n",
       "1  [[tensor(0.0328, grad_fn=<UnbindBackward0>), t...  \n",
       "\n",
       "[2 rows x 150 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed_data(df):\n",
    "    # Create empty numpy array with len(df) rows and 256 columns\n",
    "    df_embed = []\n",
    "    for k in range(len(df)):\n",
    "        df_embed.append([])\n",
    "        for n in range(len(df['code_name'][k])):\n",
    "            text_features = str(df['code_name'][k][n]) + ' ' + str(df['uom'][k][n])\n",
    "            value_features = [d for d in str(df['value'][k][n])]\n",
    "            # Embed features separately then concatenate the tensors\n",
    "            text_features = [embed(feature) for feature in text_features]\n",
    "            value_features = [embed(feature) for feature in value_features]\n",
    "            embed_input = torch.cat(text_features + value_features, dim=1)\n",
    "            # Save to df\n",
    "            df_embed[k].append(embed_input)\n",
    "    return pd.DataFrame(df_embed)\n",
    "\n",
    "# Test with first 10 rows\n",
    "df_test = df.head(2)\n",
    "df_test = embed_data(df_test)\n",
    "df_test.head()\n",
    "\n",
    "# Save to pickle\n",
    "#df_test.to_pickle('df_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
