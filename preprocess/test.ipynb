{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>DBSOURCE</th>\n",
       "      <th>FIRST_CAREUNIT</th>\n",
       "      <th>LAST_CAREUNIT</th>\n",
       "      <th>FIRST_WARDID</th>\n",
       "      <th>LAST_WARDID</th>\n",
       "      <th>INTIME</th>\n",
       "      <th>OUTTIME</th>\n",
       "      <th>LOS</th>\n",
       "      <th>...</th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>12h_obs</th>\n",
       "      <th>24h_obs</th>\n",
       "      <th>ID</th>\n",
       "      <th>code_name</th>\n",
       "      <th>code_offset</th>\n",
       "      <th>value</th>\n",
       "      <th>uom</th>\n",
       "      <th>code_order</th>\n",
       "      <th>seq_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027140</td>\n",
       "      <td>3011529</td>\n",
       "      <td>carevue</td>\n",
       "      <td>CCU</td>\n",
       "      <td>CCU</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>2152-07-23 05:34:12</td>\n",
       "      <td>2152-07-24 18:37:32</td>\n",
       "      <td>1.5440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2152-07-23 17:34:12</td>\n",
       "      <td>2152-07-24 05:34:12</td>\n",
       "      <td>3011529</td>\n",
       "      <td>[Anion Gap, Bicarbonate, Bilirubin, Total, Cho...</td>\n",
       "      <td>[78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 7...</td>\n",
       "      <td>[11.0, 25.0, 0.3, 5.9, 31.0, 108.0, 183.0, 0.7...</td>\n",
       "      <td>[mEq/L, mEq/L, mg/dL, Ratio, mg/dL, mg/dL, mg/...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1027482</td>\n",
       "      <td>3011175</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2162-03-20 17:22:48</td>\n",
       "      <td>2162-03-22 18:26:10</td>\n",
       "      <td>2.0440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2162-03-21 05:22:48</td>\n",
       "      <td>2162-03-21 17:22:48</td>\n",
       "      <td>3011175</td>\n",
       "      <td>[30060, Levofloxacin, Dextrose 5%, NS, Fentany...</td>\n",
       "      <td>[337, 397, 397, 397, 397, 397, 397, 397, 397, ...</td>\n",
       "      <td>[ , 500, 100, 100, 200, 3, 250, 500, 50, 1000,...</td>\n",
       "      <td>[ , mg, ml, ml, mcg, mg, mg, mg, ml, ml, ml, m...</td>\n",
       "      <td>[0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1011746</td>\n",
       "      <td>3013234</td>\n",
       "      <td>carevue</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2107-07-28 17:22:31</td>\n",
       "      <td>2107-08-01 11:03:44</td>\n",
       "      <td>3.7370</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2107-07-29 05:22:31</td>\n",
       "      <td>2107-07-29 17:22:31</td>\n",
       "      <td>3013234</td>\n",
       "      <td>[Acetaminophen, Alanine Aminotransferase (ALT)...</td>\n",
       "      <td>[15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...</td>\n",
       "      <td>[ , 20.0, 4.0, 64.0, 14.0, 30.0,  ,  , 23.0, 0...</td>\n",
       "      <td>[ug/mL, IU/L, g/dL, IU/L, mEq/L, IU/L,  ,  , m...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010325</td>\n",
       "      <td>3022526</td>\n",
       "      <td>metavision</td>\n",
       "      <td>MICU</td>\n",
       "      <td>MICU</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>2145-02-06 02:15:08</td>\n",
       "      <td>2145-02-07 18:47:37</td>\n",
       "      <td>1.6892</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2145-02-06 14:15:08</td>\n",
       "      <td>2145-02-07 02:15:08</td>\n",
       "      <td>3022526</td>\n",
       "      <td>[Alanine Aminotransferase (ALT), Alkaline Phos...</td>\n",
       "      <td>[222, 222, 222, 222, 222, 222, 222, 222, 222, ...</td>\n",
       "      <td>[17.0, 62.0, 11.0, 19.0, 25.0, 1.2, 8.5, 108.0...</td>\n",
       "      <td>[IU/L, IU/L, mEq/L, IU/L, mEq/L, mg/dL, mg/dL,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012708</td>\n",
       "      <td>3035542</td>\n",
       "      <td>metavision</td>\n",
       "      <td>SICU</td>\n",
       "      <td>SICU</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>2175-02-20 07:41:28</td>\n",
       "      <td>2175-02-23 10:21:01</td>\n",
       "      <td>3.1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2175-02-20 19:41:28</td>\n",
       "      <td>2175-02-21 07:41:28</td>\n",
       "      <td>3035542</td>\n",
       "      <td>[Anion Gap, Bicarbonate, Chloride, Creatine Ki...</td>\n",
       "      <td>[91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 9...</td>\n",
       "      <td>[15.0, 24.0, 98.0, 3.0, 1.8, 3.9, 133.0, 1.0, ...</td>\n",
       "      <td>[mEq/L, mEq/L, mEq/L, ng/mL, mg/dL, mEq/L, mEq...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID  ICUSTAY_ID    DBSOURCE FIRST_CAREUNIT LAST_CAREUNIT  \\\n",
       "0     1027140     3011529     carevue            CCU           CCU   \n",
       "1     1027482     3011175     carevue           MICU          MICU   \n",
       "2     1011746     3013234     carevue           MICU          MICU   \n",
       "3     1010325     3022526  metavision           MICU          MICU   \n",
       "4     1012708     3035542  metavision           SICU          SICU   \n",
       "\n",
       "   FIRST_WARDID  LAST_WARDID              INTIME             OUTTIME     LOS  \\\n",
       "0            57           57 2152-07-23 05:34:12 2152-07-24 18:37:32  1.5440   \n",
       "1            12           12 2162-03-20 17:22:48 2162-03-22 18:26:10  2.0440   \n",
       "2            52           52 2107-07-28 17:22:31 2107-08-01 11:03:44  3.7370   \n",
       "3            52           52 2145-02-06 02:15:08 2145-02-07 18:47:37  1.6892   \n",
       "4            33           33 2175-02-20 07:41:28 2175-02-23 10:21:01  3.1108   \n",
       "\n",
       "   ... ICD9_CODE             12h_obs             24h_obs       ID  \\\n",
       "0  ...       NaN 2152-07-23 17:34:12 2152-07-24 05:34:12  3011529   \n",
       "1  ...       NaN 2162-03-21 05:22:48 2162-03-21 17:22:48  3011175   \n",
       "2  ...       NaN 2107-07-29 05:22:31 2107-07-29 17:22:31  3013234   \n",
       "3  ...       NaN 2145-02-06 14:15:08 2145-02-07 02:15:08  3022526   \n",
       "4  ...       NaN 2175-02-20 19:41:28 2175-02-21 07:41:28  3035542   \n",
       "\n",
       "                                           code_name  \\\n",
       "0  [Anion Gap, Bicarbonate, Bilirubin, Total, Cho...   \n",
       "1  [30060, Levofloxacin, Dextrose 5%, NS, Fentany...   \n",
       "2  [Acetaminophen, Alanine Aminotransferase (ALT)...   \n",
       "3  [Alanine Aminotransferase (ALT), Alkaline Phos...   \n",
       "4  [Anion Gap, Bicarbonate, Chloride, Creatine Ki...   \n",
       "\n",
       "                                         code_offset  \\\n",
       "0  [78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 7...   \n",
       "1  [337, 397, 397, 397, 397, 397, 397, 397, 397, ...   \n",
       "2  [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1...   \n",
       "3  [222, 222, 222, 222, 222, 222, 222, 222, 222, ...   \n",
       "4  [91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 9...   \n",
       "\n",
       "                                               value  \\\n",
       "0  [11.0, 25.0, 0.3, 5.9, 31.0, 108.0, 183.0, 0.7...   \n",
       "1  [ , 500, 100, 100, 200, 3, 250, 500, 50, 1000,...   \n",
       "2  [ , 20.0, 4.0, 64.0, 14.0, 30.0,  ,  , 23.0, 0...   \n",
       "3  [17.0, 62.0, 11.0, 19.0, 25.0, 1.2, 8.5, 108.0...   \n",
       "4  [15.0, 24.0, 98.0, 3.0, 1.8, 3.9, 133.0, 1.0, ...   \n",
       "\n",
       "                                                 uom  \\\n",
       "0  [mEq/L, mEq/L, mg/dL, Ratio, mg/dL, mg/dL, mg/...   \n",
       "1  [ , mg, ml, ml, mcg, mg, mg, mg, ml, ml, ml, m...   \n",
       "2  [ug/mL, IU/L, g/dL, IU/L, mEq/L, IU/L,  ,  , m...   \n",
       "3  [IU/L, IU/L, mEq/L, IU/L, mEq/L, mg/dL, mg/dL,...   \n",
       "4  [mEq/L, mEq/L, mEq/L, ng/mL, mg/dL, mEq/L, mEq...   \n",
       "\n",
       "                                          code_order  seq_len  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       20  \n",
       "1  [0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, ...       36  \n",
       "2  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...      105  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...       19  \n",
       "4  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 1, ...       30  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_pickle('../train/mimiciii_df.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SUBJECT_ID', 'ICUSTAY_ID', 'DBSOURCE', 'FIRST_CAREUNIT',\n",
      "       'LAST_CAREUNIT', 'FIRST_WARDID', 'LAST_WARDID', 'INTIME', 'OUTTIME',\n",
      "       'LOS', 'GENDER', 'DOB', 'DOD', 'DOD_HOSP', 'DOD_SSN', 'EXPIRE_FLAG',\n",
      "       'age', 'readmission', 'mortality', 'los_3day', 'los_7day', 'ICD9_CODE',\n",
      "       '12h_obs', '24h_obs', 'ID', 'code_name', 'code_offset', 'value', 'uom',\n",
      "       'code_order', 'seq_len'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 436M/436M [00:31<00:00, 13.9MB/s] \n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "model_name = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "def embed(input_text):\n",
    "    tokens = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    embeddings = model(**tokens).last_hidden_state\n",
    "    pooled_embeddings = embeddings.mean(dim=1)\n",
    "    return pooled_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(0.3046, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(-0.0359, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
       "      <td>[[tensor(0.4241, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(-0.0262, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
       "      <td>[[tensor(0.4338, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2495, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2482, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2935, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2651, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.1444, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(0.0869, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3569, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2128, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3085, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2360, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.0925, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3569, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.1535, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.2128, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3085, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "      <td>[[tensor(0.3680, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 0    \\\n",
       "0  [[tensor(0.3046, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0869, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 1    \\\n",
       "0  [[tensor(-0.0359, grad_fn=<UnbindBackward0>), ...   \n",
       "1  [[tensor(0.3569, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 2    \\\n",
       "0  [[tensor(0.4241, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2128, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 3    \\\n",
       "0  [[tensor(-0.0262, grad_fn=<UnbindBackward0>), ...   \n",
       "1  [[tensor(0.3085, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 4    \\\n",
       "0  [[tensor(0.4338, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2360, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 5    \\\n",
       "0  [[tensor(0.2495, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.0925, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 6    \\\n",
       "0  [[tensor(0.2482, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3569, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 7    \\\n",
       "0  [[tensor(0.2935, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.1535, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 8    \\\n",
       "0  [[tensor(0.2651, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.2128, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 9    ...  \\\n",
       "0  [[tensor(0.1444, grad_fn=<UnbindBackward0>), t...  ...   \n",
       "1  [[tensor(0.3085, grad_fn=<UnbindBackward0>), t...  ...   \n",
       "\n",
       "                                                 140  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 141  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 142  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 143  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 144  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 145  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 146  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 147  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 148  \\\n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...   \n",
       "\n",
       "                                                 149  \n",
       "0  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...  \n",
       "1  [[tensor(0.3680, grad_fn=<UnbindBackward0>), t...  \n",
       "\n",
       "[2 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def embed_data(df):\n",
    "    # Create empty numpy array with len(df) rows and 256 columns\n",
    "    df_embed = []\n",
    "    for k in range(len(df)):\n",
    "        df_embed.append([])\n",
    "        for n in range(len(df['code_name'][k])):\n",
    "            code_name = str(df['code_name'][k][n])\n",
    "            value = str(df['value'][k][n])\n",
    "            uom = str(df['uom'][k][n])\n",
    "            features = [code_name, value, uom]\n",
    "            # Embed features separately then concatenate the tensors\n",
    "            embed_input = torch.cat([embed(feature) for feature in features])\n",
    "            # Save to df\n",
    "            df_embed[k].append(embed_input)\n",
    "    return pd.DataFrame(df_embed)\n",
    "\n",
    "# Test with first 10 rows\n",
    "df_test = df.head(2)\n",
    "df_test = embed_data(df_test)\n",
    "df_test.head()\n",
    "\n",
    "# Save to pickle\n",
    "#df_test.to_pickle('df_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
